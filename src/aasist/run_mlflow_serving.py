#!/usr/bin/env python3
"""
Simple runner script for AASIST MLflow + Serving Pipeline
Handles uploading pretrained models to MLflow and serving them
"""
import os
import sys
from pathlib import Path

def compile_mlflow_pipeline():
    """Compile the MLflow serving pipeline"""
    print("üîß Compiling AASIST MLflow + Serving Pipeline...")
    
    try:
        from kubeflow_pipeline_mlflow_serving import aasist_mlflow_serving_pipeline
        import kfp
        
        # Compile pipeline
        kfp.compiler.Compiler().compile(
            aasist_mlflow_serving_pipeline, 
            'aasist_mlflow_serving_pipeline.yaml'
        )
        
        print("‚úÖ MLflow serving pipeline compiled successfully!")
        print(f"üìÑ Generated: aasist_mlflow_serving_pipeline.yaml")
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("Make sure you have kubeflow-pipelines installed:")
        print("pip install kfp mlflow")
        return False
    except Exception as e:
        print(f"‚ùå Compilation failed: {e}")
        return False

def show_mlflow_instructions():
    """Show instructions for using the MLflow serving pipeline"""
    print("\n" + "="*70)
    print("üöÄ AASIST MLFLOW + SERVING PIPELINE - USAGE GUIDE")
    print("="*70)
    
    print("\nüìã Three Operation Modes:")
    print("  1Ô∏è‚É£  upload_only - Upload your pretrained model to MLflow")
    print("  2Ô∏è‚É£  serve_only - Load existing MLflow model and serve it")
    print("  3Ô∏è‚É£  upload_and_serve - Upload model then deploy serving")
    
    print("\nüîß Pipeline Parameters:")
    print("  ‚Ä¢ model_path: Path/URL to your pretrained model")
    print("  ‚Ä¢ model_name: Name for MLflow model registry")
    print("  ‚Ä¢ model_version: Version string (e.g., '1.0', '2.1')")
    print("  ‚Ä¢ model_stage: MLflow stage (None, Staging, Production)")
    print("  ‚Ä¢ config_name: Model config (AASIST, AASIST-L)")
    print("  ‚Ä¢ operation: Mode to run (upload_only/serve_only/upload_and_serve)")
    
    print("\nüí° Usage Examples:")
    
    print("\n  üì§ Upload Model Only:")
    print("    operation: 'upload_only'")
    print("    model_path: '/path/to/your/model.pth'")
    print("    model_name: 'my_aasist_model'")
    print("    model_version: '1.0'")
    print("    model_stage: 'Staging'")
    
    print("\n  üöÄ Serve Existing Model:")
    print("    operation: 'serve_only'")
    print("    model_name: 'my_aasist_model'")
    print("    model_version: 'latest' (or specific version)")
    print("    model_stage: 'Production'")
    
    print("\n  üîÑ Full Workflow:")
    print("    operation: 'upload_and_serve'")
    print("    model_path: 'https://example.com/model.pth'")
    print("    model_name: 'production_aasist'")
    print("    model_version: '2.0'")
    print("    model_stage: 'Production'")
    
    print("\nüìä Supported Model Paths:")
    print("  ‚Ä¢ Local files: '/path/to/model.pth'")
    print("  ‚Ä¢ Local directories: '/path/to/model_folder/'")
    print("  ‚Ä¢ HTTP URLs: 'https://example.com/model.pth'")
    print("  ‚Ä¢ Cloud storage: 's3://bucket/model.pth', 'gs://bucket/model.pth'")
    
    print("\nüéØ Perfect for:")
    print("  ‚Ä¢ Production deployment of trained models")
    print("  ‚Ä¢ Model versioning and A/B testing")
    print("  ‚Ä¢ Quick serving without retraining")
    print("  ‚Ä¢ MLflow Model Registry management")
    
    print("\n‚ö° Expected Runtime:")
    print("  ‚Ä¢ upload_only: 2-3 minutes")
    print("  ‚Ä¢ serve_only: 1-2 minutes")
    print("  ‚Ä¢ upload_and_serve: 3-5 minutes")
    
    print("\n" + "="*70)

def show_mlflow_setup():
    """Show MLflow setup instructions"""
    print("\nüîß MLflow Setup (Optional):")
    print("  If you have an MLflow tracking server, set these environment variables:")
    print("  export MLFLOW_TRACKING_URI=http://your-mlflow-server:5000")
    print("  export MLFLOW_S3_ENDPOINT_URL=http://your-s3-endpoint")
    print("  export AWS_ACCESS_KEY_ID=your-access-key")
    print("  export AWS_SECRET_ACCESS_KEY=your-secret-key")
    print("\n  Without these, MLflow will use local file storage.")

def show_example_scenarios():
    """Show example usage scenarios"""
    print("\nüìö Example Scenarios:")
    
    print("\n  üî¨ Research Scenario:")
    print("    You trained an AASIST model locally and want to:")
    print("    1. Upload it to MLflow for tracking")
    print("    2. Deploy it for testing")
    print("    ‚Üí Use: operation='upload_and_serve'")
    
    print("\n  üè≠ Production Scenario:")
    print("    You have a trained model and want to:")
    print("    1. Version it in MLflow Registry")
    print("    2. Deploy the 'Production' stage model")
    print("    ‚Üí Use: operation='upload_only' then operation='serve_only'")
    
    print("\n  üîÑ Model Update Scenario:")
    print("    You want to serve a newer version of existing model:")
    print("    1. Upload new version to MLflow")
    print("    2. Transition to Production stage")
    print("    3. Deploy the updated model")
    print("    ‚Üí Use: operation='upload_and_serve' with new version")
    
    print("\n  üß™ A/B Testing Scenario:")
    print("    You want to compare two model versions:")
    print("    1. Deploy model v1.0 as service-a")
    print("    2. Deploy model v2.0 as service-b")
    print("    3. Compare performance")
    print("    ‚Üí Use: operation='serve_only' for each version")

def check_environment():
    """Check if environment is set up correctly"""
    print("üîç Checking environment...")
    
    issues = []
    
    # Check Python version
    if sys.version_info < (3, 8):
        issues.append("Python 3.8+ required")
    
    # Check required files
    required_files = [
        "kubeflow_pipeline_mlflow_serving.py",
        "kubeflow_pipeline_demo.py"
    ]
    
    for file in required_files:
        if not os.path.exists(file):
            issues.append(f"Missing file: {file}")
    
    # Check if packages are available
    try:
        import kfp
        print(f"  ‚úì Kubeflow Pipelines: {kfp.__version__}")
    except ImportError:
        issues.append("kubeflow-pipelines not installed (pip install kfp)")
    
    try:
        import mlflow
        print(f"  ‚úì MLflow: {mlflow.__version__}")
    except ImportError:
        issues.append("mlflow not installed (pip install mlflow)")
    
    # Check MLflow configuration
    mlflow_uri = os.getenv('MLFLOW_TRACKING_URI')
    if mlflow_uri:
        print(f"  ‚úì MLflow Tracking URI: {mlflow_uri}")
    else:
        print("  ‚ÑπÔ∏è  MLflow Tracking URI: Using local file storage")
    
    if issues:
        print("‚ùå Environment issues found:")
        for issue in issues:
            print(f"  ‚Ä¢ {issue}")
        return False
    else:
        print("‚úÖ Environment looks good!")
        return True

def main():
    """Main function"""
    print("ü§ñ AASIST MLflow + Serving Pipeline Runner")
    print("=" * 50)
    
    # Check environment
    if not check_environment():
        print("\n‚ùå Please fix environment issues before proceeding")
        sys.exit(1)
    
    # Compile MLflow pipeline
    if compile_mlflow_pipeline():
        show_mlflow_instructions()
        show_mlflow_setup()
        show_example_scenarios()
        
        print(f"\nüìÅ Pipeline ready at: {os.getcwd()}")
        print("üìÑ File: aasist_mlflow_serving_pipeline.yaml")
        
        print("\nüöÄ Next Steps:")
        print("1. Upload the YAML file to your Kubeflow dashboard")
        print("2. Create a new run with your desired parameters")
        print("3. Monitor the pipeline execution")
        print("4. Access your deployed model via the serving endpoint")
        
    else:
        print("\n‚ùå Pipeline compilation failed")
        sys.exit(1)

if __name__ == "__main__":
    main() 